{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/GoogleDrive/My Drive/Fordham/machine_learning/Assignment_5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yizhizhang/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Rows: 7291, Columns: 256\n",
      "Test: Rows: 2007, Columns: 256\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import LocallyConnected1D,Reshape\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "n_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "train = pd.read_table(\"zip.train\",delim_whitespace=True,header=None)\n",
    "\n",
    "x_train, y_train = train.loc[:,1:257], train.loc[:,0]\n",
    "\n",
    "test = pd.read_table(\"zip.test\",delim_whitespace=True,header=None)\n",
    "\n",
    "x_test, y_test = test.loc[:,1:257], test.loc[:,0]\n",
    "\n",
    "\n",
    "\n",
    "print(\"Train: Rows: %d, Columns: %d\" %(x_train.shape[0], x_train.shape[1]))\n",
    "print(\"Test: Rows: %d, Columns: %d\" %(x_test.shape[0], x_test.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_93 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 17,098\n",
      "Trainable params: 17,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6561 samples, validate on 730 samples\n",
      "Epoch 1/30\n",
      "6561/6561 [==============================] - 6s 989us/step - loss: 1.0493 - acc: 0.7110 - val_loss: 0.4758 - val_acc: 0.8918\n",
      "Epoch 2/30\n",
      "6561/6561 [==============================] - 0s 42us/step - loss: 0.4292 - acc: 0.8898 - val_loss: 0.3038 - val_acc: 0.9219\n",
      "Epoch 3/30\n",
      "6561/6561 [==============================] - 0s 42us/step - loss: 0.3083 - acc: 0.9182 - val_loss: 0.2447 - val_acc: 0.9315\n",
      "Epoch 4/30\n",
      "6561/6561 [==============================] - 0s 44us/step - loss: 0.2456 - acc: 0.9339 - val_loss: 0.2151 - val_acc: 0.9342\n",
      "Epoch 5/30\n",
      "6561/6561 [==============================] - 0s 43us/step - loss: 0.2105 - acc: 0.9409 - val_loss: 0.1997 - val_acc: 0.9466\n",
      "Epoch 6/30\n",
      "6561/6561 [==============================] - 0s 43us/step - loss: 0.1836 - acc: 0.9496 - val_loss: 0.1966 - val_acc: 0.9411\n",
      "Epoch 7/30\n",
      "6561/6561 [==============================] - 0s 43us/step - loss: 0.1692 - acc: 0.9509 - val_loss: 0.1746 - val_acc: 0.9425\n",
      "Epoch 8/30\n",
      "6561/6561 [==============================] - 0s 45us/step - loss: 0.1548 - acc: 0.9582 - val_loss: 0.1690 - val_acc: 0.9493\n",
      "Epoch 9/30\n",
      "6561/6561 [==============================] - 0s 46us/step - loss: 0.1422 - acc: 0.9602 - val_loss: 0.1668 - val_acc: 0.9466\n",
      "Epoch 10/30\n",
      "6561/6561 [==============================] - 0s 65us/step - loss: 0.1332 - acc: 0.9611 - val_loss: 0.1628 - val_acc: 0.9479\n",
      "Epoch 11/30\n",
      "6561/6561 [==============================] - 0s 64us/step - loss: 0.1242 - acc: 0.9681 - val_loss: 0.1554 - val_acc: 0.9575\n",
      "Epoch 12/30\n",
      "6561/6561 [==============================] - 0s 51us/step - loss: 0.1167 - acc: 0.9695 - val_loss: 0.1509 - val_acc: 0.9548\n",
      "Epoch 13/30\n",
      "6561/6561 [==============================] - 0s 47us/step - loss: 0.1061 - acc: 0.9730 - val_loss: 0.1533 - val_acc: 0.9534\n",
      "Epoch 14/30\n",
      "6561/6561 [==============================] - 0s 44us/step - loss: 0.0993 - acc: 0.9750 - val_loss: 0.1397 - val_acc: 0.9534\n",
      "Epoch 15/30\n",
      "6561/6561 [==============================] - 0s 55us/step - loss: 0.0956 - acc: 0.9709 - val_loss: 0.1416 - val_acc: 0.9548\n",
      "Epoch 16/30\n",
      "6561/6561 [==============================] - 0s 62us/step - loss: 0.0897 - acc: 0.9762 - val_loss: 0.1460 - val_acc: 0.9562\n",
      "Epoch 17/30\n",
      "6561/6561 [==============================] - 0s 61us/step - loss: 0.0857 - acc: 0.9771 - val_loss: 0.1478 - val_acc: 0.9534\n",
      "Epoch 18/30\n",
      "6561/6561 [==============================] - 1s 93us/step - loss: 0.0801 - acc: 0.9773 - val_loss: 0.1362 - val_acc: 0.9630\n",
      "Epoch 19/30\n",
      "6561/6561 [==============================] - 1s 100us/step - loss: 0.0769 - acc: 0.9794 - val_loss: 0.1351 - val_acc: 0.9589\n",
      "Epoch 20/30\n",
      "6561/6561 [==============================] - 0s 59us/step - loss: 0.0700 - acc: 0.9805 - val_loss: 0.1321 - val_acc: 0.9575\n",
      "Epoch 21/30\n",
      "6561/6561 [==============================] - 0s 48us/step - loss: 0.0693 - acc: 0.9813 - val_loss: 0.1305 - val_acc: 0.9630\n",
      "Epoch 22/30\n",
      "6561/6561 [==============================] - 0s 45us/step - loss: 0.0646 - acc: 0.9823 - val_loss: 0.1248 - val_acc: 0.9644\n",
      "Epoch 23/30\n",
      "6561/6561 [==============================] - 0s 48us/step - loss: 0.0626 - acc: 0.9845 - val_loss: 0.1291 - val_acc: 0.9603\n",
      "Epoch 24/30\n",
      "6561/6561 [==============================] - 0s 49us/step - loss: 0.0586 - acc: 0.9851 - val_loss: 0.1224 - val_acc: 0.9616\n",
      "Epoch 25/30\n",
      "6561/6561 [==============================] - 0s 51us/step - loss: 0.0553 - acc: 0.9845 - val_loss: 0.1176 - val_acc: 0.9630\n",
      "Epoch 26/30\n",
      "6561/6561 [==============================] - 0s 50us/step - loss: 0.0485 - acc: 0.9889 - val_loss: 0.1186 - val_acc: 0.9630\n",
      "Epoch 27/30\n",
      "6561/6561 [==============================] - 0s 65us/step - loss: 0.0506 - acc: 0.9880 - val_loss: 0.1258 - val_acc: 0.9616\n",
      "Epoch 28/30\n",
      "6561/6561 [==============================] - 0s 57us/step - loss: 0.0440 - acc: 0.9889 - val_loss: 0.1316 - val_acc: 0.9630\n",
      "Epoch 29/30\n",
      "6561/6561 [==============================] - 0s 46us/step - loss: 0.0416 - acc: 0.9913 - val_loss: 0.1294 - val_acc: 0.9603\n",
      "Epoch 30/30\n",
      "6561/6561 [==============================] - 0s 44us/step - loss: 0.0427 - acc: 0.9880 - val_loss: 0.1243 - val_acc: 0.9658\n",
      "Test loss: 0.2922424869542254\n",
      "Test accuracy: 0.9267563528841148\n"
     ]
    }
   ],
   "source": [
    "# build model 1: one hidden layer, 12 hidden units fully connected. test accuracy: 0.9268\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(64, activation='relu', use_bias=True,kernel_initializer='uniform',\n",
    "                 bias_initializer='random_uniform',input_shape=(256,)))\n",
    "model1.add(Dropout(0.1))\n",
    "model1.add(Dense(n_classes, activation='softmax'))\n",
    "model1.summary()\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model1.fit(x_train, y_train,\n",
    "                    epochs=30,\n",
    "                    verbose=1,\n",
    "                    batch_size=300,\n",
    "                    validation_split=0.1)\n",
    "score = model1.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Conv1D, MaxPooling1D,Embedding, Activation\n",
    "\n",
    "X_train = np.expand_dims(x_train, axis=2)\n",
    "X_test = np.expand_dims(x_test,axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7291 samples, validate on 2007 samples\n",
      "Epoch 1/12\n",
      "7291/7291 [==============================] - 31s 4ms/step - loss: 2.2484 - acc: 0.2020 - val_loss: 2.0141 - val_acc: 0.2825\n",
      "Epoch 2/12\n",
      "7291/7291 [==============================] - 31s 4ms/step - loss: 1.0507 - acc: 0.6701 - val_loss: 0.5525 - val_acc: 0.8286\n",
      "Epoch 3/12\n",
      "7291/7291 [==============================] - 30s 4ms/step - loss: 0.3372 - acc: 0.8995 - val_loss: 0.4320 - val_acc: 0.8724\n",
      "Epoch 4/12\n",
      "7291/7291 [==============================] - 30s 4ms/step - loss: 0.2505 - acc: 0.9276 - val_loss: 0.3667 - val_acc: 0.9013\n",
      "Epoch 5/12\n",
      "7291/7291 [==============================] - 30s 4ms/step - loss: 0.2119 - acc: 0.9407 - val_loss: 0.3393 - val_acc: 0.9138\n",
      "Epoch 6/12\n",
      "7291/7291 [==============================] - 31s 4ms/step - loss: 0.1867 - acc: 0.9490 - val_loss: 0.3220 - val_acc: 0.9193\n",
      "Epoch 7/12\n",
      "7291/7291 [==============================] - 31s 4ms/step - loss: 0.1637 - acc: 0.9525 - val_loss: 0.3200 - val_acc: 0.9148\n",
      "Epoch 8/12\n",
      "7291/7291 [==============================] - 31s 4ms/step - loss: 0.1461 - acc: 0.9583 - val_loss: 0.3019 - val_acc: 0.9238\n",
      "Epoch 9/12\n",
      "7291/7291 [==============================] - 31s 4ms/step - loss: 0.1341 - acc: 0.9608 - val_loss: 0.3004 - val_acc: 0.9253\n",
      "Epoch 10/12\n",
      "7291/7291 [==============================] - 30s 4ms/step - loss: 0.1240 - acc: 0.9635 - val_loss: 0.3029 - val_acc: 0.9188\n",
      "Epoch 11/12\n",
      "7291/7291 [==============================] - 30s 4ms/step - loss: 0.1109 - acc: 0.9675 - val_loss: 0.2777 - val_acc: 0.9273\n",
      "Epoch 12/12\n",
      "7291/7291 [==============================] - 31s 4ms/step - loss: 0.0979 - acc: 0.9719 - val_loss: 0.2950 - val_acc: 0.9273\n",
      "Test loss: 0.2949986047541614\n",
      "Test accuracy: 0.9272546089877521\n"
     ]
    }
   ],
   "source": [
    "# build model 2: two hidden layers locally connected. test accuracy: 0.9272\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Conv1D(64,9,activation = \"sigmoid\",input_shape=(256,1)))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Conv1D(16,25,activation = \"sigmoid\"))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(n_classes,activation='softmax'))\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"Adadelta\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model2.fit(X_train, y_train,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(X_test, y_test))\n",
    "score = model2.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7291 samples, validate on 2007 samples\n",
      "Epoch 1/12\n",
      "7291/7291 [==============================] - 711s 97ms/step - loss: 13.3139 - acc: 0.0911 - val_loss: 13.8143 - val_acc: 0.0732\n",
      "Epoch 2/12\n",
      "7291/7291 [==============================] - 623s 85ms/step - loss: 13.2521 - acc: 0.0905 - val_loss: 12.4872 - val_acc: 0.0732\n",
      "Epoch 3/12\n",
      "7291/7291 [==============================] - 814s 112ms/step - loss: 12.3234 - acc: 0.1040 - val_loss: 12.4428 - val_acc: 0.0827\n",
      "Epoch 4/12\n",
      "7291/7291 [==============================] - 749s 103ms/step - loss: 12.1256 - acc: 0.1613 - val_loss: 12.4312 - val_acc: 0.1096\n",
      "Epoch 5/12\n",
      "7291/7291 [==============================] - 651s 89ms/step - loss: 12.0381 - acc: 0.1954 - val_loss: 12.2554 - val_acc: 0.2167\n",
      "Epoch 6/12\n",
      "7291/7291 [==============================] - 653s 90ms/step - loss: 11.9600 - acc: 0.2215 - val_loss: 12.2454 - val_acc: 0.2277\n",
      "Epoch 7/12\n",
      "7291/7291 [==============================] - 649s 89ms/step - loss: 11.9283 - acc: 0.2369 - val_loss: 12.5745 - val_acc: 0.1634\n",
      "Epoch 8/12\n",
      "7291/7291 [==============================] - 644s 88ms/step - loss: 11.9090 - acc: 0.2417 - val_loss: 12.2740 - val_acc: 0.2252\n",
      "Epoch 9/12\n",
      "7291/7291 [==============================] - 602s 83ms/step - loss: 11.9042 - acc: 0.2433 - val_loss: 12.2526 - val_acc: 0.2287\n",
      "Epoch 10/12\n",
      "7291/7291 [==============================] - 620s 85ms/step - loss: 11.8923 - acc: 0.2456 - val_loss: 12.2471 - val_acc: 0.2312\n",
      "Epoch 11/12\n",
      "7291/7291 [==============================] - 660s 90ms/step - loss: 11.8802 - acc: 0.2476 - val_loss: 12.3020 - val_acc: 0.2182\n",
      "Epoch 12/12\n",
      "7291/7291 [==============================] - 613s 84ms/step - loss: 11.8826 - acc: 0.2481 - val_loss: 12.2718 - val_acc: 0.2287\n",
      "Test loss: 12.27182954285474\n",
      "Test accuracy: 0.2286995516066297\n"
     ]
    }
   ],
   "source": [
    "# build model 3: two hidden layers, locally connected with weight sharing\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import Conv1D, Input, Activation\n",
    "from keras.models import Model\n",
    "\n",
    "main_input = Input(shape=(256,1), dtype='float32', name='main_input')\n",
    "\n",
    "x1 = Conv1D(64,9,activation = \"sigmoid\",use_bias = True,\n",
    "            bias_initializer = \"random_uniform\")(main_input)\n",
    "x2 = Conv1D(64,9,activation = \"sigmoid\",use_bias = True,\n",
    "            bias_initializer = \"random_uniform\")(main_input)\n",
    "\n",
    "x3 = LocallyConnected1D(16, 25,activation = \"sigmoid\",use_bias = True)(x1)\n",
    "x4 = LocallyConnected1D(16, 25,activation = \"sigmoid\",use_bias = True)(x2)\n",
    "\n",
    "x = keras.layers.concatenate([x3, x4])\n",
    "x_flatten = Flatten()(x)\n",
    "main_output = Dense(n_classes, activation='softmax',name='main_output')(x_flatten)\n",
    "\n",
    "model3 = Model(inputs=main_input, outputs=main_output)\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model3.fit(X_train, y_train,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(X_test, y_test))\n",
    "score = model3.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6561 samples, validate on 730 samples\n",
      "Epoch 1/30\n",
      "6561/6561 [==============================] - 19s 3ms/step - loss: 0.9945 - acc: 0.6758 - val_loss: 0.3721 - val_acc: 0.8945\n",
      "Epoch 2/30\n",
      "6561/6561 [==============================] - 5s 716us/step - loss: 0.3263 - acc: 0.9023 - val_loss: 0.2559 - val_acc: 0.9178\n",
      "Epoch 3/30\n",
      "6561/6561 [==============================] - 5s 737us/step - loss: 0.1974 - acc: 0.9425 - val_loss: 0.1896 - val_acc: 0.9356\n",
      "Epoch 4/30\n",
      "6561/6561 [==============================] - 5s 791us/step - loss: 0.1687 - acc: 0.9505 - val_loss: 0.1636 - val_acc: 0.9548\n",
      "Epoch 5/30\n",
      "6561/6561 [==============================] - 5s 781us/step - loss: 0.1146 - acc: 0.9665 - val_loss: 0.1568 - val_acc: 0.9507\n",
      "Epoch 6/30\n",
      "6561/6561 [==============================] - 5s 719us/step - loss: 0.0917 - acc: 0.9730 - val_loss: 0.1398 - val_acc: 0.9575\n",
      "Epoch 7/30\n",
      "6561/6561 [==============================] - 5s 826us/step - loss: 0.0668 - acc: 0.9809 - val_loss: 0.1614 - val_acc: 0.9521\n",
      "Epoch 8/30\n",
      "6561/6561 [==============================] - 5s 747us/step - loss: 0.0622 - acc: 0.9828 - val_loss: 0.1482 - val_acc: 0.9575\n",
      "Epoch 9/30\n",
      "6561/6561 [==============================] - 6s 849us/step - loss: 0.0451 - acc: 0.9873 - val_loss: 0.1115 - val_acc: 0.9630\n",
      "Epoch 10/30\n",
      "6561/6561 [==============================] - 5s 808us/step - loss: 0.0387 - acc: 0.9886 - val_loss: 0.0933 - val_acc: 0.9753\n",
      "Epoch 11/30\n",
      "6561/6561 [==============================] - 5s 764us/step - loss: 0.0254 - acc: 0.9934 - val_loss: 0.1479 - val_acc: 0.9575\n",
      "Epoch 12/30\n",
      "6561/6561 [==============================] - 5s 719us/step - loss: 0.0208 - acc: 0.9944 - val_loss: 0.1920 - val_acc: 0.9452\n",
      "Epoch 13/30\n",
      "6561/6561 [==============================] - 6s 849us/step - loss: 0.0275 - acc: 0.9915 - val_loss: 0.1062 - val_acc: 0.9740\n",
      "Epoch 14/30\n",
      "6561/6561 [==============================] - 5s 823us/step - loss: 0.0134 - acc: 0.9965 - val_loss: 0.1206 - val_acc: 0.9699\n",
      "Epoch 15/30\n",
      "6561/6561 [==============================] - 5s 715us/step - loss: 0.0165 - acc: 0.9959 - val_loss: 0.0997 - val_acc: 0.9712\n",
      "Epoch 16/30\n",
      "6561/6561 [==============================] - 5s 735us/step - loss: 0.0095 - acc: 0.9985 - val_loss: 0.0970 - val_acc: 0.9781\n",
      "Epoch 17/30\n",
      "6561/6561 [==============================] - 5s 734us/step - loss: 0.0093 - acc: 0.9977 - val_loss: 0.1575 - val_acc: 0.9562\n",
      "Epoch 18/30\n",
      "6561/6561 [==============================] - 4s 677us/step - loss: 0.0092 - acc: 0.9985 - val_loss: 0.1166 - val_acc: 0.9712\n",
      "Epoch 19/30\n",
      "6561/6561 [==============================] - 5s 774us/step - loss: 0.0165 - acc: 0.9968 - val_loss: 0.0994 - val_acc: 0.9753\n",
      "Epoch 20/30\n",
      "6561/6561 [==============================] - 5s 722us/step - loss: 0.0035 - acc: 0.9997 - val_loss: 0.1166 - val_acc: 0.9726\n",
      "Epoch 21/30\n",
      "6561/6561 [==============================] - 5s 783us/step - loss: 0.0069 - acc: 0.9988 - val_loss: 0.2000 - val_acc: 0.9562\n",
      "Epoch 22/30\n",
      "6561/6561 [==============================] - 4s 669us/step - loss: 0.0066 - acc: 0.9988 - val_loss: 0.1210 - val_acc: 0.9712\n",
      "Epoch 23/30\n",
      "6561/6561 [==============================] - 6s 852us/step - loss: 0.0096 - acc: 0.9982 - val_loss: 0.1401 - val_acc: 0.9671\n",
      "Epoch 24/30\n",
      "6561/6561 [==============================] - 4s 671us/step - loss: 0.0034 - acc: 0.9992 - val_loss: 0.1199 - val_acc: 0.9740\n",
      "Epoch 25/30\n",
      "6561/6561 [==============================] - 5s 750us/step - loss: 0.0016 - acc: 0.9998 - val_loss: 0.1093 - val_acc: 0.9767\n",
      "Epoch 26/30\n",
      "6561/6561 [==============================] - 4s 670us/step - loss: 0.0077 - acc: 0.9980 - val_loss: 0.1173 - val_acc: 0.9712\n",
      "Epoch 27/30\n",
      "6561/6561 [==============================] - 5s 771us/step - loss: 0.0025 - acc: 0.9997 - val_loss: 0.1219 - val_acc: 0.9712\n",
      "Epoch 28/30\n",
      "6561/6561 [==============================] - 4s 623us/step - loss: 0.0104 - acc: 0.9983 - val_loss: 0.1597 - val_acc: 0.9658\n",
      "Epoch 29/30\n",
      "6561/6561 [==============================] - 4s 592us/step - loss: 0.0034 - acc: 0.9992 - val_loss: 0.1114 - val_acc: 0.9712\n",
      "Epoch 30/30\n",
      "6561/6561 [==============================] - 4s 589us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.1168 - val_acc: 0.9753\n",
      "Test loss: 0.33406158753227133\n",
      "Test accuracy: 0.9427005482005075\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy: 0.9427\n",
    "from keras.optimizers import SGD\n",
    "model4 = Sequential()\n",
    "model4.add(Conv1D(64,9,activation = \"relu\",use_bias = True,bias_initializer='random_uniform',\n",
    "                 kernel_initializer='uniform',input_shape=(256,1)))\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(100, activation='relu', use_bias=True,bias_initializer='random_uniform',\n",
    "                 kernel_initializer='uniform'))\n",
    "model4.add(Dense(100, activation='tanh', use_bias=True,bias_initializer='random_uniform',\n",
    "                 kernel_initializer='uniform'))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Dense(n_classes, activation='softmax'))\n",
    "#sgd = SGD(lr = 0.001, decay = 1e-7, momentum = 0.9)\n",
    "\n",
    "\n",
    "model4.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model4.fit(X_train, y_train,\n",
    "                    epochs=30,\n",
    "                    verbose=1,\n",
    "                    batch_size=300,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "score = model4.evaluate(X_test,y_test,verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6561 samples, validate on 730 samples\n",
      "Epoch 1/30\n",
      "6561/6561 [==============================] - 13s 2ms/step - loss: 1.2342 - acc: 0.6170 - val_loss: 0.6646 - val_acc: 0.7959\n",
      "Epoch 2/30\n",
      "6561/6561 [==============================] - 1s 105us/step - loss: 0.4577 - acc: 0.8679 - val_loss: 0.3352 - val_acc: 0.8932\n",
      "Epoch 3/30\n",
      "6561/6561 [==============================] - 1s 98us/step - loss: 0.2981 - acc: 0.9142 - val_loss: 0.2746 - val_acc: 0.9096\n",
      "Epoch 4/30\n",
      "6561/6561 [==============================] - 0s 73us/step - loss: 0.2406 - acc: 0.9317 - val_loss: 0.2179 - val_acc: 0.9342\n",
      "Epoch 5/30\n",
      "6561/6561 [==============================] - 1s 77us/step - loss: 0.2006 - acc: 0.9415 - val_loss: 0.2279 - val_acc: 0.9301\n",
      "Epoch 6/30\n",
      "6561/6561 [==============================] - 0s 70us/step - loss: 0.1818 - acc: 0.9489 - val_loss: 0.1955 - val_acc: 0.9438\n",
      "Epoch 7/30\n",
      "6561/6561 [==============================] - 0s 76us/step - loss: 0.1557 - acc: 0.9552 - val_loss: 0.1897 - val_acc: 0.9411\n",
      "Epoch 8/30\n",
      "6561/6561 [==============================] - 1s 88us/step - loss: 0.1389 - acc: 0.9607 - val_loss: 0.1773 - val_acc: 0.9466\n",
      "Epoch 9/30\n",
      "6561/6561 [==============================] - 0s 75us/step - loss: 0.1210 - acc: 0.9657 - val_loss: 0.1562 - val_acc: 0.9548\n",
      "Epoch 10/30\n",
      "6561/6561 [==============================] - 1s 86us/step - loss: 0.1174 - acc: 0.9651 - val_loss: 0.1666 - val_acc: 0.9521\n",
      "Epoch 11/30\n",
      "6561/6561 [==============================] - 0s 70us/step - loss: 0.0903 - acc: 0.9729 - val_loss: 0.1569 - val_acc: 0.9575\n",
      "Epoch 12/30\n",
      "6561/6561 [==============================] - 1s 82us/step - loss: 0.0845 - acc: 0.9761 - val_loss: 0.1517 - val_acc: 0.9534\n",
      "Epoch 13/30\n",
      "6561/6561 [==============================] - 1s 144us/step - loss: 0.0760 - acc: 0.9781 - val_loss: 0.1591 - val_acc: 0.9562\n",
      "Epoch 14/30\n",
      "6561/6561 [==============================] - 1s 87us/step - loss: 0.0631 - acc: 0.9809 - val_loss: 0.1383 - val_acc: 0.9603\n",
      "Epoch 15/30\n",
      "6561/6561 [==============================] - 1s 80us/step - loss: 0.0553 - acc: 0.9826 - val_loss: 0.1511 - val_acc: 0.9548\n",
      "Epoch 16/30\n",
      "6561/6561 [==============================] - 1s 87us/step - loss: 0.0509 - acc: 0.9852 - val_loss: 0.1473 - val_acc: 0.9616\n",
      "Epoch 17/30\n",
      "6561/6561 [==============================] - 1s 85us/step - loss: 0.0407 - acc: 0.9887 - val_loss: 0.1238 - val_acc: 0.9644\n",
      "Epoch 18/30\n",
      "6561/6561 [==============================] - 1s 166us/step - loss: 0.0341 - acc: 0.9910 - val_loss: 0.1460 - val_acc: 0.9644\n",
      "Epoch 19/30\n",
      "6561/6561 [==============================] - 1s 137us/step - loss: 0.0286 - acc: 0.9919 - val_loss: 0.1765 - val_acc: 0.9521\n",
      "Epoch 20/30\n",
      "6561/6561 [==============================] - 1s 150us/step - loss: 0.0314 - acc: 0.9907 - val_loss: 0.1300 - val_acc: 0.9671\n",
      "Epoch 21/30\n",
      "6561/6561 [==============================] - 1s 107us/step - loss: 0.0259 - acc: 0.9934 - val_loss: 0.2156 - val_acc: 0.9384\n",
      "Epoch 22/30\n",
      "6561/6561 [==============================] - 1s 90us/step - loss: 0.0216 - acc: 0.9948 - val_loss: 0.1432 - val_acc: 0.9630\n",
      "Epoch 23/30\n",
      "6561/6561 [==============================] - 1s 86us/step - loss: 0.0212 - acc: 0.9948 - val_loss: 0.1453 - val_acc: 0.9630\n",
      "Epoch 24/30\n",
      "6561/6561 [==============================] - 1s 81us/step - loss: 0.0158 - acc: 0.9965 - val_loss: 0.1695 - val_acc: 0.9521\n",
      "Epoch 25/30\n",
      "6561/6561 [==============================] - 1s 83us/step - loss: 0.0171 - acc: 0.9956 - val_loss: 0.1469 - val_acc: 0.9671\n",
      "Epoch 26/30\n",
      "6561/6561 [==============================] - 1s 79us/step - loss: 0.0084 - acc: 0.9983 - val_loss: 0.1525 - val_acc: 0.9644\n",
      "Epoch 27/30\n",
      "6561/6561 [==============================] - 1s 83us/step - loss: 0.0119 - acc: 0.9974 - val_loss: 0.2228 - val_acc: 0.9507\n",
      "Epoch 28/30\n",
      "6561/6561 [==============================] - 1s 109us/step - loss: 0.0143 - acc: 0.9966 - val_loss: 0.1453 - val_acc: 0.9658\n",
      "Epoch 29/30\n",
      "6561/6561 [==============================] - 1s 110us/step - loss: 0.0142 - acc: 0.9957 - val_loss: 0.1559 - val_acc: 0.9671\n",
      "Epoch 30/30\n",
      "6561/6561 [==============================] - 1s 84us/step - loss: 0.0057 - acc: 0.9991 - val_loss: 0.1543 - val_acc: 0.9671\n",
      "Test loss: 0.3708825511881069\n",
      "Test accuracy: 0.9332336822313994\n"
     ]
    }
   ],
   "source": [
    "# test accuracy: 0.9347\n",
    "from keras.optimizers import SGD\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(100,activation = \"relu\",use_bias = True,bias_initializer='random_uniform',\n",
    "                 kernel_initializer='uniform',input_shape=(256,)))\n",
    "#model4.add(Dropout(0.2))\n",
    "model4.add(Dense(100, activation='relu', use_bias=True,bias_initializer='random_uniform',\n",
    "                 kernel_initializer='uniform'))\n",
    "#model4.add(Dropout(0.2))\n",
    "model4.add(Dense(100, activation='tanh', use_bias=True,bias_initializer='random_uniform',\n",
    "                 kernel_initializer='uniform'))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Dense(n_classes, activation='softmax'))\n",
    "#sgd = SGD(lr = 0.001, decay = 1e-7, momentum = 0.9)\n",
    "\n",
    "\n",
    "model4.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model4.fit(x_train, y_train,\n",
    "                    epochs=30,\n",
    "                    verbose=1,\n",
    "                    batch_size=300,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "score = model4.evaluate(x_test,y_test,verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6561 samples, validate on 730 samples\n",
      "Epoch 1/30\n",
      "6561/6561 [==============================] - 30s 5ms/step - loss: 1.0817 - acc: 0.6525 - val_loss: 0.3603 - val_acc: 0.8918\n",
      "Epoch 2/30\n",
      "6561/6561 [==============================] - 18s 3ms/step - loss: 0.3134 - acc: 0.9040 - val_loss: 0.2706 - val_acc: 0.9178\n",
      "Epoch 3/30\n",
      "6561/6561 [==============================] - 18s 3ms/step - loss: 0.2208 - acc: 0.9357 - val_loss: 0.2315 - val_acc: 0.9315\n",
      "Epoch 4/30\n",
      "6561/6561 [==============================] - 19s 3ms/step - loss: 0.1634 - acc: 0.9556 - val_loss: 0.1391 - val_acc: 0.9548\n",
      "Epoch 5/30\n",
      "6561/6561 [==============================] - 19s 3ms/step - loss: 0.1269 - acc: 0.9625 - val_loss: 0.1340 - val_acc: 0.9616\n",
      "Epoch 6/30\n",
      "6561/6561 [==============================] - 18s 3ms/step - loss: 0.1027 - acc: 0.9677 - val_loss: 0.1106 - val_acc: 0.9726\n",
      "Epoch 7/30\n",
      "6561/6561 [==============================] - 18s 3ms/step - loss: 0.0808 - acc: 0.9758 - val_loss: 0.0867 - val_acc: 0.9685\n",
      "Epoch 8/30\n",
      "6561/6561 [==============================] - 18s 3ms/step - loss: 0.0690 - acc: 0.9788 - val_loss: 0.0933 - val_acc: 0.9740\n",
      "Epoch 9/30\n",
      "6561/6561 [==============================] - 18s 3ms/step - loss: 0.0501 - acc: 0.9840 - val_loss: 0.1086 - val_acc: 0.9616\n",
      "Epoch 10/30\n",
      "6561/6561 [==============================] - 18s 3ms/step - loss: 0.0413 - acc: 0.9881 - val_loss: 0.0916 - val_acc: 0.9726\n",
      "Epoch 11/30\n",
      "6561/6561 [==============================] - 19s 3ms/step - loss: 0.0379 - acc: 0.9887 - val_loss: 0.0878 - val_acc: 0.9699\n",
      "Epoch 12/30\n",
      "6561/6561 [==============================] - 18s 3ms/step - loss: 0.0239 - acc: 0.9939 - val_loss: 0.0922 - val_acc: 0.9699\n",
      "Epoch 13/30\n",
      "6561/6561 [==============================] - 19s 3ms/step - loss: 0.0232 - acc: 0.9945 - val_loss: 0.0977 - val_acc: 0.9712\n",
      "Epoch 14/30\n",
      "6561/6561 [==============================] - 19s 3ms/step - loss: 0.0183 - acc: 0.9945 - val_loss: 0.1312 - val_acc: 0.9589\n",
      "Epoch 15/30\n",
      "6561/6561 [==============================] - 18s 3ms/step - loss: 0.0162 - acc: 0.9950 - val_loss: 0.0928 - val_acc: 0.9740\n",
      "Epoch 16/30\n",
      "6561/6561 [==============================] - 18s 3ms/step - loss: 0.0173 - acc: 0.9939 - val_loss: 0.0661 - val_acc: 0.9795\n",
      "Epoch 17/30\n",
      "6561/6561 [==============================] - 19s 3ms/step - loss: 0.0114 - acc: 0.9970 - val_loss: 0.0658 - val_acc: 0.9795\n",
      "Epoch 18/30\n",
      "6561/6561 [==============================] - 19s 3ms/step - loss: 0.0145 - acc: 0.9963 - val_loss: 0.0675 - val_acc: 0.9767\n",
      "Epoch 19/30\n",
      "6561/6561 [==============================] - 18s 3ms/step - loss: 0.0091 - acc: 0.9983 - val_loss: 0.0832 - val_acc: 0.9726\n",
      "Epoch 20/30\n",
      "6561/6561 [==============================] - 18s 3ms/step - loss: 0.0178 - acc: 0.9953 - val_loss: 0.0639 - val_acc: 0.9781\n",
      "Epoch 21/30\n",
      "6561/6561 [==============================] - 18s 3ms/step - loss: 0.0050 - acc: 0.9992 - val_loss: 0.1044 - val_acc: 0.9712\n",
      "Epoch 22/30\n",
      "6561/6561 [==============================] - 18s 3ms/step - loss: 0.0084 - acc: 0.9973 - val_loss: 0.0798 - val_acc: 0.9822\n",
      "Epoch 23/30\n",
      "6561/6561 [==============================] - 18s 3ms/step - loss: 0.0121 - acc: 0.9971 - val_loss: 0.0645 - val_acc: 0.9808\n",
      "Epoch 24/30\n",
      "6561/6561 [==============================] - 19s 3ms/step - loss: 0.0043 - acc: 0.9995 - val_loss: 0.0606 - val_acc: 0.9822\n",
      "Epoch 25/30\n",
      "6561/6561 [==============================] - 19s 3ms/step - loss: 0.0087 - acc: 0.9982 - val_loss: 0.0739 - val_acc: 0.9753\n",
      "Epoch 26/30\n",
      "6561/6561 [==============================] - 19s 3ms/step - loss: 0.0057 - acc: 0.9989 - val_loss: 0.0572 - val_acc: 0.9877\n",
      "Epoch 27/30\n",
      "6561/6561 [==============================] - 18s 3ms/step - loss: 0.0029 - acc: 0.9995 - val_loss: 0.0656 - val_acc: 0.9849\n",
      "Epoch 28/30\n",
      "6561/6561 [==============================] - 18s 3ms/step - loss: 0.0105 - acc: 0.9974 - val_loss: 0.0663 - val_acc: 0.9836\n",
      "Epoch 29/30\n",
      "6561/6561 [==============================] - 18s 3ms/step - loss: 0.0067 - acc: 0.9983 - val_loss: 0.0503 - val_acc: 0.9877\n",
      "Epoch 30/30\n",
      "6561/6561 [==============================] - 19s 3ms/step - loss: 0.0043 - acc: 0.9989 - val_loss: 0.0558 - val_acc: 0.9863\n",
      "Test loss: 0.26386571023009964\n",
      "Test accuracy: 0.9526656702732529\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy: 0.9527\n",
    "model5 = Sequential()\n",
    "model5.add(Conv1D(64,9,activation = \"relu\",use_bias = True,bias_initializer='random_uniform',\n",
    "                 kernel_initializer='uniform',input_shape=(256,1)))\n",
    "\n",
    "model5.add(Conv1D(16,25, activation='relu', use_bias=True,bias_initializer='random_uniform',\n",
    "                 kernel_initializer='uniform'))\n",
    "model5.add(Dropout(0.1))\n",
    "model5.add(Flatten())\n",
    "model5.add(Dense(100, activation='relu', use_bias=True,bias_initializer='random_uniform',\n",
    "                 kernel_initializer='uniform'))\n",
    "model5.add(Dense(100, activation='tanh', use_bias=True,bias_initializer='random_uniform',\n",
    "                 kernel_initializer='uniform'))\n",
    "model5.add(Dropout(0.1))\n",
    "model5.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "model5.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model5.fit(X_train, y_train,\n",
    "                    epochs=30,\n",
    "                    verbose=1,\n",
    "                    batch_size=300,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "score = model5.evaluate(X_test,y_test,verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
