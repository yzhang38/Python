{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7e2e22578949c65fe3173b635977924372194935"
   },
   "source": [
    "**Purpose of this project:**\n",
    "Use regression techniques to predict sales price. \n",
    "\n",
    "**Procedures:**\n",
    "1. Data preprocessing:\n",
    "    a. Dealing with missing values\n",
    "    b. Data transformation\n",
    "    c. Handling categorical data\n",
    "    \n",
    "2. Feature selection: After comparing the results of selection based on VIF, random forest predictor importance, and correlations and pca, I decide to use correlation and pca to do feature selection. 1. keep continuous features that has significant correlation with the outcome. 2. Standardized data. 3.Use PCA to do dimension reduction.\n",
    "\n",
    "3. Model Fitting: After trying the following methods: Linear Regression, Lasso regression, Ridge regression, Random Forest, XGBoost, SVR linear, I decided to use XGBoost.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "house_price = pd.read_csv(\"../input/train.csv\")\n",
    "house_price.describe()\n",
    "\n",
    "print(house_price.columns)\n",
    "#(1460,81)\n",
    "house_price.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "64abce52ecc5e10651623c4d7e3debc49c8d433a"
   },
   "source": [
    " 1.a\n",
    " Check missing data and the meaning of NA's ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d4998b6353c0e3d5c1ea4aa83bb89635407bf04d"
   },
   "outputs": [],
   "source": [
    "hp_NA = house_price.isnull().sum()\n",
    "print(hp_NA[hp_NA!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "38f8cb22900cf00c3b273be1c2673b1fb0819f10"
   },
   "outputs": [],
   "source": [
    "def fillmissing(house_price):\n",
    "    house_price['LotFrontage']=house_price.groupby('Street')['LotFrontage'].transform(\n",
    "        lambda x: x.fillna(x.mean()))\n",
    "    house_price['Alley']=house_price['Alley'].fillna('NoAlley')\n",
    "    house_price['MasVnrType']=house_price['MasVnrType'].fillna('None')\n",
    "    house_price['MasVnrArea']=house_price['MasVnrArea'].fillna(0)\n",
    "    for col in ('BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2'):\n",
    "        house_price[col]=house_price[col].fillna('NoBase')\n",
    "    house_price['Electrical']=house_price['Electrical'].fillna(\n",
    "        house_price['Electrical'].mode()[0])\n",
    "    house_price['FireplaceQu']=house_price['FireplaceQu'].fillna('NoFireplace')\n",
    "    for col in ('GarageType','GarageFinish','GarageQual','GarageCond'):\n",
    "        house_price[col]=house_price[col].fillna('NoGarage')\n",
    "    house_price['GarageYrBlt']=house_price['GarageYrBlt'].fillna(0)\n",
    "    house_price['PoolQC']=house_price['PoolQC'].fillna('NoPool')\n",
    "    house_price['Fence']=house_price['Fence'].fillna('NoFence')\n",
    "    house_price['MiscFeature']=house_price['MiscFeature'].fillna('None')\n",
    "    return house_price\n",
    "\n",
    "house_price = fillmissing(house_price )\n",
    "hp_NA = house_price.isnull().sum()\n",
    "print(hp_NA[hp_NA!=0])\n",
    "house_price.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "667e4b64ff8911893ae25580f24bcb47fab051d0"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "test = fillmissing(test)\n",
    "test['MSZoning']=test['MSZoning'].fillna(test['MSZoning'].mode()[0])\n",
    "test['Utilities']=test['Utilities'].fillna(test['Utilities'].mode()[0])\n",
    "test['Exterior1st']=test['Exterior1st'].fillna(test['Exterior1st'].mode()[0])\n",
    "test['Exterior2nd']=test['Exterior2nd'].fillna(test['Exterior2nd'].mode()[0])\n",
    "test['BsmtFinSF1']=test['BsmtFinSF1'].fillna(0)\n",
    "test['BsmtFinSF2']=test['BsmtFinSF2'].fillna(0)\n",
    "test['BsmtUnfSF']=test['BsmtUnfSF'].fillna(0)\n",
    "test['TotalBsmtSF']=test['TotalBsmtSF'].fillna(0)\n",
    "test['BsmtFullBath']=test['BsmtFullBath'].fillna(0)\n",
    "test['BsmtHalfBath']=test['BsmtHalfBath'].fillna(0)\n",
    "test['KitchenQual']=test['KitchenQual'].fillna(test['KitchenQual'].mode()[0])\n",
    "test['GarageCars']=test['GarageCars'].fillna(0)\n",
    "test['GarageArea']=test['GarageArea'].fillna(0)\n",
    "test['SaleType']=test['SaleType'].fillna(test['SaleType'].mode()[0])\n",
    "test['Functional']=test['Functional'].fillna(test['Functional'].mode()[0])\n",
    "test_NA = test.isnull().sum()\n",
    "print(test_NA[test_NA!=0])\n",
    "test_id=test.Id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bc94072efc5081b942a98f1c8cfa31f8cdd2a855"
   },
   "source": [
    "1.b\n",
    "Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "42c2890f84851f73b815246cb8cbaa9b4b420523"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "sns.distplot(house_price.SalePrice,kde=True)\n",
    "plt.title(\"SalePrice distribution\")\n",
    "plt.show()\n",
    "# The distribution of y violates the assumption of normal distribution\n",
    "# Do log transformation on y\n",
    "house_price['log_y'] =np.log1p(house_price.SalePrice) \n",
    "sns.distplot(house_price.log_y,kde=True)\n",
    "plt.title(\"Log(1+SalePrice) distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b6159c569aca1b4a4e37de8630cdf7fe20c6acc0"
   },
   "source": [
    "Find correlations and its p value between continuous features and the outcome variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e47bb58b73ceec5e844dba8eda4dc84243f9ac06"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "x_r = house_price[[\"LotFrontage\",\"LotArea\", \"OverallQual\", \n",
    "                   \"OverallCond\", \"YearBuilt\", \"YearRemodAdd\", \n",
    "                   \"MasVnrArea\", \"BsmtFinSF1\", \"BsmtFinSF2\", \n",
    "                   \"BsmtUnfSF\", \"TotalBsmtSF\", \"1stFlrSF\", \n",
    "                   \"2ndFlrSF\", \"LowQualFinSF\", \"GrLivArea\", \n",
    "                   \"BsmtFullBath\", \"BsmtHalfBath\", \"FullBath\", \n",
    "                   \"HalfBath\", \"TotRmsAbvGrd\", \"Fireplaces\", \n",
    "                   \"GarageYrBlt\", \"GarageCars\", \"GarageArea\", \n",
    "                   \"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\", \n",
    "                   \"3SsnPorch\", \"ScreenPorch\", \"PoolArea\", \n",
    "                   \"MiscVal\", \"MoSold\", \"YrSold\"]]\n",
    "y_r = house_price.log_y\n",
    "\n",
    "a = pd.DataFrame(columns=[\"r\",\"p\"], index = x_r.columns)\n",
    "for col in x_r.columns:\n",
    "    b = pearsonr(x_r[col],y_r) \n",
    "    if b[1] < 0.05:\n",
    "        a.loc[col] = pd.Series({\"r\":b[0], \"p\":b[1]})\n",
    "        print (col, \" r:\", b[0], \" p:\", b[1])\n",
    "a.sort_values(by = [\"r\"],ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete continuous variables that have no significant (p>0.01) correlation with the outcome variable. \n",
    "Transform categorical variable to dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a00d700f1ce186e1f3be342f35310c8068f43586"
   },
   "outputs": [],
   "source": [
    "hp_drop = house_price.drop([\"Id\",\"OverallCond\",\"BsmtFinSF2\",\"LowQualFinSF\",\n",
    "                  \"BsmtHalfBath\",\"MiscVal\",\"YrSold\",\"SalePrice\"],axis=1)\n",
    "\n",
    "tt_drop = test.drop([\"Id\",\"OverallCond\",\"BsmtFinSF2\",\"LowQualFinSF\",\n",
    "                  \"BsmtHalfBath\",\"MiscVal\",\"YrSold\"],axis=1)\n",
    "\n",
    "X,y = hp_drop.drop(['log_y'],axis=1),hp_drop.log_y\n",
    "\n",
    "alldata = pd.concat([X,tt_drop],ignore_index=True,sort=False)\n",
    "all_one_hot = pd.get_dummies(alldata)\n",
    "train = all_one_hot.loc[0:(X.shape[0]-1),]\n",
    "tt = all_one_hot.loc[X.shape[0]:(all_one_hot.shape[0]-1),]\n",
    "\n",
    "print(train.shape,tt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize remaining features and use PCA to transform data. Only keep 6 principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "05a5e7770f12ab00ae0282db43a3c469f86fe35c"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1st component:9.83744091e-01, 2nd: 5.08583965e-03, 3rd: 3.38481930e-03, \n",
    "# 4th:2.77136722e-03, 5th: 1.96914612e-03, 6th: 1.75122582e-03. \n",
    "\n",
    "pipe_pc = Pipeline([(\"scl\", StandardScaler()),\n",
    "                    (\"pca\", PCA(n_components=6))])\n",
    "\n",
    "train_pc = pipe_pc.fit_transform(train)\n",
    "test_pc = pipe_pc.transform(tt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to do 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "529019b50fd370f369c59787c99b4e97d8e5f9e8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def rmse_cv(model, X, y):\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=100)\n",
    "    rmse = np.sqrt(-cross_val_score(model,X,y, cv=cv, scoring=\"neg_mean_squared_error\"))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eb232761891e074c9dd38acbf6639641a63df0c5"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rgr = XGBRegressor(random_state=100)\n",
    "para_range = np.linspace(start= 0.0001,stop=1, num=100)\n",
    "params =[{'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)],\n",
    "         'learning_rate': para_range}]\n",
    "rgr_random = GridSearchCV(estimator = rgr, \n",
    "                        param_grid = params, cv = 5, \n",
    "                        verbose=2,  \n",
    "                        scoring = 'neg_mean_squared_error',n_jobs = -1)\n",
    "\n",
    "rgr_random.fit(train_pc,y)\n",
    "print('best parameters: %s' %rgr_random.best_params_)\n",
    "print('rmse: %.3f' %np.sqrt(-rgr_random.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Compare the results between the tuned model and base model. Use tuned model to make prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "15434ab1a2f3d042208c62db1714089efeae4b06"
   },
   "outputs": [],
   "source": [
    "\n",
    "from xgboost import XGBRegressor\n",
    "xg_best = XGBRegressor(n_estimator=200, learning_rate=0.0809,random_state=100)\n",
    "score = rmse_cv(xg_best,train_pc,y)\n",
    "\n",
    "print('train: mean rmse: %.3f, std rmse: %.3f' %(score.mean(),score.std()))\n",
    "\n",
    "\n",
    "xg_base=XGBRegressor(n_estimator=200,random_state=100)\n",
    "score = rmse_cv(xg_base,train_pc,y)\n",
    "\n",
    "print(score.mean(), score.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "25a6379748282cf067eb8cd20d194e38693cb0c9"
   },
   "source": [
    "Xgboost has the lowest rmse, so we use xgboost to predict the test data. After than, transform the log y back to y and export data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ad563a429f447628f34fd4e999926c21690ebe2b"
   },
   "outputs": [],
   "source": [
    "xg_best = XGBRegressor(n_estimator=200, learning_rate=0.0809,random_state=100)\n",
    "xg_best.fit(train_pc,y)\n",
    "y_pred = xg_best.predict(test_pc)\n",
    "y_test = np.expm1(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6f900719274d0ce47c92e42c4869165350c265ab"
   },
   "outputs": [],
   "source": [
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['Id'] = test_id\n",
    "sub['SalePrice'] = y_test\n",
    "sub.to_csv('submission3.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
